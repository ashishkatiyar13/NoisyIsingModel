{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shfMGDnBHvyj"
   },
   "outputs": [],
   "source": [
    "import numpy.random as rand\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import timeit\n",
    "import time\n",
    "from numpy.linalg import inv\n",
    "from tempfile import TemporaryFile\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJSzyPvrVmAw"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate the probability mass function (PMF) of Ising Model given the weight matrix W and 0 mean random variables.\n",
    "\n",
    "The PMF P(x) for a given input x is proportional to exp(Transpose(x) W x/2)\n",
    "\n",
    "Input: \n",
    "Weight matrix - W\n",
    "\n",
    "Output: \n",
    "Probability Distribution - prob\n",
    "\"\"\"\n",
    "def gen_prob(W):\n",
    "    d = W.shape[0] \n",
    "    prob = np.zeros(2**d)\n",
    "    for i in range(2**d):\n",
    "        x = np.ones((d,1))*-1\n",
    "        x[d - len(list(bin(i)[2:])):, 0] = np.array(list(bin(i)[2:])).astype(int)*2-1\n",
    "        prob[i] = np.exp(np.matmul(np.transpose(x), np.matmul(W, x))*0.5)\n",
    "    prob = prob/sum(prob)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ibnw-GzlhW5"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate the probability distribution of Ising Model given the weight matrix W and non-mean random variables.\n",
    "\n",
    "The PMF P(x) for a given input x is proportional to exp(Transpose(x) W x/2 + Transpose(x) b)\n",
    "\n",
    "Input: \n",
    "Weight matrix - W, \n",
    "Bias - b\n",
    "\n",
    "Output: \n",
    "Probability Distribution - prob\n",
    "\"\"\"\n",
    "def gen_prob_b(W, b):\n",
    "    d = W.shape[0] \n",
    "    prob = np.zeros(2**d)\n",
    "    for i in range(2**d):\n",
    "        x = np.ones((d,1))*-1\n",
    "        x[d - len(list(bin(i)[2:])):, 0] = np.array(list(bin(i)[2:])).astype(int)*2-1\n",
    "        prob[i] = np.exp(np.matmul(np.transpose(x), np.matmul(W, x))*0.5 + np.dot(np.transpose(x), b))\n",
    "    prob = prob/sum(prob)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AG9JUeJoWGjC"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate random samples given a probability mass function.\n",
    "\n",
    "Inputs: \n",
    "probability mass function - prob, \n",
    "number of samples - num_samples\n",
    "\n",
    "Output: \n",
    "samples (shape - (num_samples x d) where d is the number of nodes) - bin_samples\n",
    "\"\"\"\n",
    "def gen_samples(prob, num_samples):\n",
    "    d = int(np.log2(len(prob)))\n",
    "    samples = rand.choice(2**d, size = (num_samples,), replace = True, p = prob)\n",
    "    bin_samples = np.ones((num_samples, d))*-1\n",
    "    for i in range(len(samples)):\n",
    "        bin_samples[i, d - len(list(bin(samples[i])[2:])):] = np.array(list(bin(samples[i])[2:])).astype(int)*2-1\n",
    "    return bin_samples\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBp4gBPUWG-4"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate the Weight matrix for a binary tree structured Ising model.\n",
    "\n",
    "Input: \n",
    "Number of nodes (of the form 2^l-1 where l is the number of levels) - num_nodes\n",
    "Minimum weight - min_w\n",
    "Maximum weight - max_w\n",
    "\n",
    "Output:\n",
    "Weight matrix - W\n",
    "\"\"\"\n",
    "def gen_binary_tree_W(params):\n",
    "    num_nodes, min_w, max_w = params['d'], params['min_w'], params['max_w']\n",
    "    W = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range((num_nodes-1)/2):\n",
    "        W[i,2*i+1] = rand.uniform(min_w, max_w)\n",
    "        W[2*i+1,i] = W[i,2*i+1]\n",
    "        W[i,2*i+2] = rand.uniform(min_w, max_w)\n",
    "        W[2*i+2,i] = W[i,2*i+2]\n",
    "    return W\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dj_ZTJAfTZ2J"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate the Weight matrix for a star structured Ising model with one internal node and the remaining leaf nodes.\n",
    "\n",
    "Input: \n",
    "Number of nodes - num_nodes\n",
    "Minimum weight - min_w\n",
    "Maximum weight - max_w\n",
    "\n",
    "Output:\n",
    "Weight matrix - W\n",
    "\"\"\"\n",
    "def gen_star_W(params):\n",
    "    num_nodes, min_w, max_w = params['d'], params['min_w'], params['max_w']\n",
    "    W = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes-1):\n",
    "      W[0, i+1] = rand.uniform(min_w, max_w)\n",
    "      W[i+1, 0] = W[0,i+1]\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBBA15xYLkf8"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate the Weight matrix for a chain structured Ising model.\n",
    "\n",
    "Input: \n",
    "Number of nodes - num_nodes\n",
    "Minimum weight - min_w\n",
    "Maximum weight - max_w\n",
    "\n",
    "Output:\n",
    "Weight matrix - W\n",
    "\"\"\"\n",
    "def gen_chain_W(params):\n",
    "    num_nodes, min_w, max_w = params['d'], params['min_w'], params['max_w']\n",
    "    W = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes-1):\n",
    "        W[i, i+1] = rand.uniform(min_w, max_w)\n",
    "        W[i+1, i] = W[i, i+1]\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-riRrRDLnZH"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checks if a set of 4 nodes is non-star structured. If it is, it returns the separation of the nodes in 2 groups of 2 nodes each.\n",
    "\n",
    "Input:\n",
    "The empirical covariance matrix of all the nodes - emp_cov\n",
    "The set of 4 nodes that are checked for non-star - nodes\n",
    "The threshold for the categorization as a star/non-star from Table 1 in the paper - eps\n",
    "\n",
    "Output:\n",
    "If the set of 4 nodes is non-star or not - non_star\n",
    "If they are, return the two pairs - fin_pair1, fin_pair2\n",
    "If not return empty lists - [], []\n",
    "\n",
    "\"\"\"\n",
    "def is_non_star(emp_cov, nodes, eps):\n",
    "#     print eps\n",
    "    non_star = False\n",
    "    fin_pair1 = [-1,-1]\n",
    "    fin_pair2 = [-1,-1]\n",
    "    for i in range(3):\n",
    "        for j in range(i+1, 4):\n",
    "            pair1 = [nodes[i], nodes[j]]\n",
    "            pair2 = list(set(nodes) - set(pair1))\n",
    "            if (emp_cov[pair1[0], pair2[0]]*emp_cov[pair1[1], pair2[1]])/\\\n",
    "                (emp_cov[pair1[0], pair2[1]]*emp_cov[pair1[1], pair2[0]]) > eps\\\n",
    "                and (emp_cov[pair1[0], pair2[0]]*emp_cov[pair1[1], pair2[1]])/\\\n",
    "                (emp_cov[pair1[0], pair1[1]]*emp_cov[pair2[0], pair2[1]])<eps:                \n",
    "                non_star = True\n",
    "                fin_pair1[:] = pair1[:]\n",
    "                fin_pair2[:] = pair2[:]\n",
    "    if non_star == True:\n",
    "        return non_star, fin_pair1, fin_pair2\n",
    "    else:\n",
    "        return non_star, [], []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ery1-H1QhxG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a subtree and a node - root, this function returns all the nodes in the equivalence class containting root in (subtree U root).\n",
    "\n",
    "Inputs:\n",
    "emp_cov - Empirical covariance matrix of all the nodes.\n",
    "root - The node whose equivalence class we intend to find.\n",
    "prox1 - Proximal Set 1 of all the nodes.\n",
    "prox2 - Proximal Set 2 of all the nodes.\n",
    "subtree - The subset of the nodes considered while finding the equivalence class.\n",
    "eps - The threshold used while classifying a set of 4 nodes as star/non-star.\n",
    "\n",
    "Output:\n",
    "EC - The list of nodes in the same equivalence cluster as root when we consider the node only in (subtree U root).\n",
    "\"\"\"\n",
    "def find_EC(emp_cov, root, prox1, prox2, subtree, eps):\n",
    "    EC = []\n",
    "    if (len(subtree) <= 2):\n",
    "        return subtree\n",
    "    common_nodes_big = list(set(prox1[root])& set(subtree))\n",
    "    \n",
    "    for i in common_nodes_big:\n",
    "        is_leaf = True\n",
    "        k1 = i\n",
    "        count = 0\n",
    "        while k1==i or k1 == root:\n",
    "            k1 = common_nodes_big[count]\n",
    "            count +=1\n",
    "        sig_i_k1 = emp_cov[i,k1]\n",
    "        sig_root_k1 = emp_cov[root, k1]\n",
    "        common_nodes = list(set(prox2[root])& set(prox2[i]) & set(prox2[k1]) & set(subtree))\n",
    "        for k2 in common_nodes:\n",
    "            sig_root_k2 = emp_cov[root, k2] \n",
    "            sig_i_k2 = emp_cov[i,k2]\n",
    "            if min((sig_i_k1*sig_root_k2) / (sig_i_k2*sig_root_k1),\\\n",
    "                   (sig_i_k2*sig_root_k1) / (sig_i_k1*sig_root_k2))<eps:\n",
    "                is_leaf = False\n",
    "        if is_leaf:\n",
    "            EC.append(i)       \n",
    "    return EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EA3Ld0bWLXM"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A subroutine used to merge nodes in the same subtree.  \n",
    "\"\"\"\n",
    "def merge_splits(split1, split2):\n",
    "    len_common_r_e = len(split1)\n",
    "    merged = [-1]*len_common_r_e\n",
    "    for i in range(len_common_r_e):\n",
    "        if split1[i] == 1 or split2[i] == 1:\n",
    "            merged[i] = 1\n",
    "    return merged      \n",
    "  \n",
    "\"\"\"\n",
    "Split the nodes in the common proximal sets of the root node and the external node into multiple subtrees.\n",
    "\n",
    "Input:\n",
    "emp_cov - Empirical covariance matrix of all the nodes.\n",
    "root - Internal node\n",
    "ext - Leaf node\n",
    "prox1 - Proximal Set 1 of all the nodes.\n",
    "prox2 - Proximal Set 2 of all the nodes.\n",
    "prohibited - The set of nodes assigned to other subtrees in the previous iterations that should not be considered while splitting the current subtree.\n",
    "eps - The threshold used while classifying a set of 4 nodes as star/non-star.\n",
    "\n",
    "Output:\n",
    "subtrees - A list of subtrees\n",
    "\n",
    "\"\"\"  \n",
    "def split_subtree(emp_cov, root, ext, prox1, prox2, prohibited, eps):\n",
    "    common_root_ext = list(set(prox1[root]) & set(prox1[ext]) )\n",
    "    len_common_r_e = len(common_root_ext)\n",
    "    split = [[-1]*len_common_r_e for i in range(len_common_r_e)]\n",
    "    for i in range(len_common_r_e):\n",
    "        split[i][i] = 1\n",
    "    \n",
    "    for i in range(len_common_r_e):\n",
    "        node_i = common_root_ext[i]\n",
    "        if node_i in prohibited: \n",
    "            split[i][i] = -1\n",
    "            continue      \n",
    "        for j in range(len_common_r_e):\n",
    "            node_j = common_root_ext[j]\n",
    "            if node_j == node_i or node_j not in prox2[node_i]:\n",
    "                continue\n",
    "            nodes = [root, ext, node_i, node_j]\n",
    "            status, pair1, pair2 = is_non_star(emp_cov, nodes, eps)\n",
    "            if status and root in pair2 and ext in pair2:\n",
    "                if node_j in prohibited:\n",
    "                    split[i][:] = [-1]*len_common_r_e\n",
    "                    break\n",
    "                split[i][j] = 1\n",
    "\n",
    "    deleted = []\n",
    "    for i in range(len_common_r_e):\n",
    "        first = 1\n",
    "        for j in range(len_common_r_e):\n",
    "            if j in deleted:\n",
    "                continue\n",
    "            if split[j][i] == 1:\n",
    "                if first == 1:\n",
    "                    first = 0\n",
    "                    ind = j\n",
    "                else:\n",
    "                    split[ind] = merge_splits(split[ind], split[j])\n",
    "                    deleted.append(j)   \n",
    "    subtrees = []\n",
    "    for j in range(len_common_r_e):\n",
    "        if j in deleted:\n",
    "            continue\n",
    "        subtree_j = []\n",
    "        for k in range(len_common_r_e):\n",
    "            if split[j][k] == 1:               \n",
    "                subtree_j.append(common_root_ext[k])\n",
    "        subtrees.append(subtree_j)\n",
    "    \n",
    "    return subtrees\n",
    "\"\"\"\n",
    "The initialization of the algorithm where it finds a node with atleast one more node in its equivalence class.\n",
    "\n",
    "Input:\n",
    "emp_cov - Empirical covariance matrix of all the nodes.\n",
    "prox1 - Proximal Set 1 of all the nodes.\n",
    "prox2 - Proximal Set 2 of all the nodes.\n",
    "eps - The threshold used while classifying a set of 4 nodes as star/non-star.\n",
    "edges - The list of edges discovered by the algorithm. This is updated when the first equivalence cluster with more than one nodes is discovered.\n",
    "prohibited - The set of nodes in the discovered equivalence cluster is added to the prohibited set so that they are not assigned to subtrees in the future.\n",
    "\n",
    "Output:\n",
    "i - A node with more than one nodes in its equivalence cluster.\n",
    "EC_init - The list of all the nodes in the equivalence cluster containing i.\n",
    "edges - The updated list of edges.\n",
    "\"\"\"\n",
    "  \n",
    "def alg_init(emp_cov, prox1, prox2, eps, edges, prohibited):\n",
    "    n = emp_cov.shape[0]\n",
    "    subtree = range(n)\n",
    "    for i in range(n):\n",
    "        EC_init = find_EC(emp_cov, i, prox1, prox2, subtree, eps)\n",
    "        len_EC_init = len(EC_init)\n",
    "        if len_EC_init > 0:\n",
    "            prohibited.append(i)\n",
    "            for j in EC_init:\n",
    "                edges.append([i,j])\n",
    "                prohibited.append(j)\n",
    "            break\n",
    "    return i, EC_init, edges\n",
    "  \n",
    "\"\"\"\n",
    "The recursive step of the algorithm. It updates the edges.\n",
    "\n",
    "Input:\n",
    "emp_cov - Empirical covariance matrix of all the nodes.\n",
    "prox1 - Proximal Set 1 of all the nodes.\n",
    "prox2 - Proximal Set 2 of all the nodes.\n",
    "eps - The threshold used while classifying a set of 4 nodes as star/non-star.\n",
    "edges - The list of edges discovered by the algorithm. \n",
    "xi - The node xext has an edge with.\n",
    "xext - The leaf node.\n",
    "prohibited - The set of nodes assigned previously to other subtrees.\n",
    "\"\"\"  \n",
    "def full_alg_recurse(emp_cov, prox1, prox2, eps, edges, xi, xext, prohibited):\n",
    "    \n",
    "    sub_subtrees = split_subtree(emp_cov, xext, xi, prox1, prox2, prohibited, eps)\n",
    "    for i in sub_subtrees:\n",
    "        for j in i:\n",
    "            prohibited.append(j)\n",
    "    num_sub_subtrees = len(sub_subtrees)  \n",
    "    for i in range(num_sub_subtrees):\n",
    "        local_prohibit = [-1]*len(prohibited)\n",
    "        local_prohibit[:] = prohibited[:]\n",
    "        for j in sub_subtrees[i]:\n",
    "            local_prohibit.remove(j)\n",
    "        EC = find_EC(emp_cov, xi, prox1, prox2, sub_subtrees[i], eps)\n",
    "        len_EC = len(EC)\n",
    "        \n",
    "        for j in range(1, len_EC):\n",
    "            edges.append([EC[j], EC[0]])\n",
    "            local_prohibit.append(EC[j])\n",
    "        if len_EC>0:\n",
    "            edges.append([xi, EC[0]])\n",
    "            local_prohibit.append(EC[0])\n",
    "            full_alg_recurse(emp_cov, prox1, prox2, eps, edges, EC[0], xi, local_prohibit)\n",
    "\n",
    "            \n",
    "\"\"\"\n",
    "Generates the two prox sets.\n",
    "\"\"\"\n",
    "def get_prox(emp_corr, thres1, thres2):\n",
    "    prox1 = []\n",
    "    prox2 = []\n",
    "    n = emp_corr.shape[0]\n",
    "    for i in range(n):\n",
    "        prox1_i = []\n",
    "        prox2_i = []\n",
    "        for j in range(n):\n",
    "            if j == i:\n",
    "                continue\n",
    "            if abs(emp_corr[i,j])>thres1:\n",
    "                prox1_i.append(j)\n",
    "            if abs(emp_corr[i,j])>thres2:\n",
    "                prox2_i.append(j)\n",
    "        prox1.append(prox1_i)\n",
    "        prox2.append(prox2_i)\n",
    "    return prox1, prox2\n",
    "  \n",
    "  \n",
    "\"\"\"\n",
    "This is the complete algorithm. Returns the edges learnt by the algorithm. If the algorithm fails at this stage, it returns an error.\n",
    "\n",
    "Inputs:\n",
    "sample_sig - Sample covariance matrix.\n",
    "prox1 - Proximal Set 1 of all the nodes.\n",
    "prox2 - Proximal Set 2 of all the nodes.\n",
    "rho_max - Maximum correlation between 2 consecutive nodes.\n",
    "\n",
    "Output:\n",
    "edges - Edges learnt by the algorithm.\n",
    "error - Returns an error if the algorithm fails\n",
    "\n",
    "\"\"\"  \n",
    "def find_tree(sample_sig, prox1, prox2, rho_max):\n",
    "    n = sample_sig.shape[0]\n",
    "    edges = []\n",
    "    eps = (1+rho_max**2)/2\n",
    "    prohibited = []\n",
    "    root, EC_init, edges = alg_init(sample_sig, prox1, prox2, eps, edges, prohibited)\n",
    "    error = 0\n",
    "    if len(EC_init) == 0:\n",
    "        return [], -1\n",
    "    subtree = range(n)\n",
    "    subtree = list(set(subtree) - set(EC_init))\n",
    "    full_alg_recurse(sample_sig, prox1, prox2, eps, edges, root, EC_init[0], prohibited)\n",
    "    return edges, error\n",
    "  \n",
    "\"\"\"\n",
    "This removes any redundant edges.\n",
    "\"\"\"\n",
    "def deduplicate_edges(edges):\n",
    "    for i in edges:\n",
    "        for j in edges:\n",
    "            if i==j:\n",
    "                continue\n",
    "            if set(i) == set(j):\n",
    "                edges.remove(j)\n",
    "    return edges\n",
    "\n",
    "\"\"\"\n",
    "Constructs all the trees in the equivalence class if the tree is chain-structured.\n",
    "\"\"\"\n",
    "def chain_edge_sets(params):\n",
    "    d = params['d']\n",
    "    edges_1 = []\n",
    "    for i in range(d-1):\n",
    "        edges_1.append(frozenset([i,i+1]))\n",
    "    edges_1_set = set(edges_1)\n",
    "    edges_1[1] = frozenset([0,2])\n",
    "    edges_2_set = set(edges_1)\n",
    "    edges_1[-2] = frozenset([d-3, d-1])\n",
    "    edges_3_set = set(edges_1)\n",
    "    edges_1[1] = frozenset([1,2])\n",
    "    edges_4_set = set(edges_1)\n",
    "    return [edges_1_set, edges_2_set, edges_3_set, edges_4_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWqXazLuQ7yt"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Constructs all the trees in the equivalence class if the tree is star-structured.\n",
    "\"\"\"\n",
    "def star_edge_sets(params):\n",
    "    d = params['d']\n",
    "    edge_set_list = []\n",
    "    for i in range(d):\n",
    "        edge_list = []\n",
    "        for j in range(d):\n",
    "            if j == i:\n",
    "                continue\n",
    "            edge_list.append(frozenset([i,j]))\n",
    "        edge_set = set(edge_list)\n",
    "        edge_set_list.append(edge_set)\n",
    "          \n",
    "    return edge_set_list\n",
    "\n",
    "def edges_as_set_of_sets(edges):\n",
    "    edges_set = set([frozenset(i) for i in edges])\n",
    "    return edges_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i6087diwaGrm"
   },
   "outputs": [],
   "source": [
    "def corr(W, b1, b2):\n",
    "    mean1 = (np.exp(b1)*(np.exp(W+b2)+np.exp(-W-b2)) - np.exp(-b1)*(np.exp(-W+b2)+np.exp(W-b2)))\\\n",
    "                /(np.exp(b1)*(np.exp(W+b2)+np.exp(-W-b2)) + np.exp(-b1)*(np.exp(-W+b2)+np.exp(W-b2)))\n",
    "    mean2 = (np.exp(b2)*(np.exp(W+b1)+np.exp(-W-b1)) - np.exp(-b2)*(np.exp(-W+b1)+np.exp(W-b1)))\\\n",
    "                /(np.exp(b2)*(np.exp(W+b1)+np.exp(-W-b1)) + np.exp(-b2)*(np.exp(-W+b1)+np.exp(W-b1)))\n",
    "    E_X1_X2 = (np.exp(W)*(np.exp(b1+b2)+np.exp(-b1-b2)) - np.exp(-W)*(np.exp(-b2+b1)+np.exp(b2-b1)))\\\n",
    "              /(np.exp(W)*(np.exp(b1+b2)+np.exp(-b1-b2)) + np.exp(-W)*(np.exp(-b2+b1)+np.exp(b2-b1)))\n",
    "    corr = (E_X1_X2 - mean1*mean2)/np.sqrt((1-mean1**2)*(1-mean2**2))\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCDIu1_dWmR9"
   },
   "outputs": [],
   "source": [
    "# Initializing parameters and variables\n",
    "\n",
    "def init_params():\n",
    "    params = {}                                         # Dictionary of Parameters\n",
    "    params['shape'] = 'star'                            # graph structure: 'star', 'chain'\n",
    "    params['b_list'] = [0.0, 0.2, 0.4]                  # list of bias values\n",
    "    params['num_samples_list'] = range(400, 3001, 1000) # list of number of samples\n",
    "    params['d'] = 11                                    # number of nodes\n",
    "    params['min_w'] = 0.7                               # minimum edge weight in the graph\n",
    "    params['max_w'] = 1.2                               # maximum edge weight in the graph\n",
    "    params['num_iter'] = 50                             # number of runs\n",
    "    params['q_min'] = 0                                 # minimum probability of corruption for a node\n",
    "    params['q_max'] = 0.1                               # maximum probability of corruption for a node\n",
    "    \n",
    "    results = {}                                        # Dictionary of results\n",
    "    results['num_error_list'] = []                      # List of list for number of errors \n",
    "                                                        # size = len(params['b_list']) x len(num_samples_list)\n",
    "    \n",
    "    return params, results\n",
    "\n",
    "# Defining main function\n",
    "def main():\n",
    "    params, results = init_params()\n",
    "    for mod_b in params['b_list']:\n",
    "        time_start = time.time()\n",
    "        \n",
    "        rand.seed(1)\n",
    "        b = rand.uniform(mod_b, mod_b, params['d'])\n",
    "        q = rand.uniform(params['q_min'], params['q_max'], params['d'])\n",
    "        \n",
    "        # Generating the weight matrix, Here we only consider two graph structures: star and chain\n",
    "        # The code for other potential graph structures can be placed here\n",
    "        # It should have two components: \n",
    "        # i) a function to generate the weight matrix W\n",
    "        # ii) a function to find the equivalence class for that graph structure\n",
    "        if params['shape'] == 'chain':\n",
    "            W = gen_chain_W(params)\n",
    "            equivalence_class = chain_edge_sets(params)\n",
    "        elif params['shape'] == 'star':\n",
    "            W = gen_star_W(params)\n",
    "            equivalence_class = star_edge_sets(params)\n",
    "        \n",
    "        # Generate the probability distribution of Ising Model given the weight matrix W \n",
    "        # and non-mean random variables.\n",
    "        prob = gen_prob_b(W, b)\n",
    "        \n",
    "        results['num_error_list'].append([])\n",
    "        \n",
    "        for num_samples in params['num_samples_list']:\n",
    "            \n",
    "            num_error = 0\n",
    "\n",
    "            for itr in range(params['num_iter']):\n",
    "                # Generate samples from the given distribution\n",
    "                samples = gen_samples(prob, num_samples)\n",
    "                noise = np.empty([num_samples, params['d']], dtype = int)\n",
    "                \n",
    "                for i in range(params['d']):\n",
    "                    noise[:, i] = stats.bernoulli.rvs(1 - q[i], size = num_samples) * 2 - 1\n",
    "                    \n",
    "                # Generate noisy samples from clean samples\n",
    "                noisy_samples = np.multiply(noise, samples)\n",
    "                \n",
    "                # Statistics of the noisy samples\n",
    "                sample_mu =  np.array(1.0 / num_samples*np.sum(noisy_samples, axis=0)).reshape((1, params['d']))\n",
    "                mu_max = np.max(sample_mu)\n",
    "                emp_corr = 1.0 / (num_samples-1)*(np.matmul(np.transpose(noisy_samples), noisy_samples) - np.dot(np.transpose(sample_mu), sample_mu))\n",
    "                corr_min = abs(corr(params['min_w'], mod_b, mod_b))\n",
    "                corr_max = abs(corr(params['max_w'], 0, 0))\n",
    "                \n",
    "                # Define the algorithm parameters\n",
    "                thres1 = (corr_min)**4 * (1 - 2 * params['q_max']) ** 2*(1-mu_max**2) / 2.0\n",
    "                thres2 = min([thres1 * (1 - 2 * params['q_max']) * np.sqrt((1-mu_max**2)) / corr_max, thres1])\n",
    "                \n",
    "                # Run the algorithm subroutines: \n",
    "                # i) finding the proximal set \n",
    "                # ii) finding the equivalence tree\n",
    "                prox1, prox2 = get_prox(emp_corr, thres1, thres2)\n",
    "                edges, error = find_tree(emp_corr, prox1, prox2, corr_max)\n",
    "                \n",
    "                # Verify if the edges lie in the equivalence class\n",
    "                edges_set = edges_as_set_of_sets(edges)\n",
    "                \n",
    "                # Calculate if the edge set was recovered correctly upto the equivalence class\n",
    "                if edges_set not in equivalence_class or error ==-1:\n",
    "                    num_error += 1\n",
    "            \n",
    "            # Store the results for a given bias value for all the samples in num_samples_list\n",
    "            results['num_error_list'][len(results['num_error_list'])-1].append(num_error)\n",
    "        \n",
    "        print(\"Time Elapsed\", time.time() - time_start, params['d'], num_samples, results['num_error_list'])\n",
    "    \n",
    "    return results\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "rB_1WpGe_qjn",
    "outputId": "3b9cba57-1e06-49b6-d97e-245d9ec71ee0"
   },
   "outputs": [],
   "source": [
    "# Here is where you run the code. \n",
    "results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjq9Qcw8_pqH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9EPQxSa-iY5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RobustTreeStructIsingModels.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
